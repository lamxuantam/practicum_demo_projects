{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\"> \r\n",
    "<h3>TASK</h3>\r\n",
    "I was assigned to give <a href=\"https://drive.google.com/file/d/1ifkw712e55_WBvPfKvIl0fil8XlI7YEO/view?usp=sharing\">a general analysis of Youtube trending-videos</a>.\r\n",
    "<br>\r\n",
    "<br>Because the same process needed to be repeated weekly, <a href=\"https://public.tableau.com/app/profile/lam.xuan.tam/viz/Youtubetrending-videosanalysis/Dashboard\">an interactive Dashboard</a> of interested metrics and <a href=\"#script\">a simple script</a> for dataset update were also created.\r\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PIPELINE SCRIPT FILE FOR DATASET UPDATE <a id=\"script\"></a>\r\n",
    "\r\n",
    "README INSTRUCTION:  \r\n",
    "\r\n",
    "Run “pipelinescript.py” file and specify folder path to save new/updated dataset. (Note: you’ll need to install Python to run the script.)  \r\n",
    "Example of command line: \r\n",
    "python C:\\<folder path of .py file>\\pipelinescript .py --path=C:/<folder path to save .csv file>/\r\n",
    "\r\n",
    "Open .twbx file and go to Data Source tab.\r\n",
    "On Connection -  “trending_by_time”, choose Edit Connection and connect to new/updated .csv file location.  \r\n",
    "\r\n",
    "The Dashboard is now updated with new dataset!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To add a new cell, type '# %%'\r\n",
    "# To add a new markdown cell, type '# %% [markdown]'\r\n",
    "# %%\r\n",
    "#!/usr/bin/python\r\n",
    "\r\n",
    "# Importing libraries\r\n",
    "import pandas as pd\r\n",
    "from sqlalchemy import create_engine\r\n",
    "\r\n",
    "import sys\r\n",
    "import getopt\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "\r\n",
    "    # Define folder path in local machine\r\n",
    "    unixOptions = \"p:\"  \r\n",
    "    gnuOptions = [\"path=\"]\r\n",
    "\r\n",
    "    fullCmdArguments = sys.argv\r\n",
    "    argumentList = fullCmdArguments[1:]\r\n",
    "    try:  \r\n",
    "        arguments, values = getopt.getopt(argumentList, unixOptions, gnuOptions)\r\n",
    "    except getopt.error as err:  \r\n",
    "        print (str(err))\r\n",
    "        sys.exit(2)\r\n",
    "\r\n",
    "    for currentArgument, currentValue in arguments:  \r\n",
    "        if currentArgument in (\"-p\", \"--path\"):\r\n",
    "            path = currentValue\r\n",
    "\r\n",
    "    # Defining parameters for connecting to the database;\r\n",
    "    # db_config information requested from database administrator\r\n",
    "    db_config = {'user': '*******',     # username\r\n",
    "                'pwd': '*****',         # password\r\n",
    "                'host': '*********',    # server address\r\n",
    "                'port': 6***,            # connection port\r\n",
    "                'db': 'data-analyst-youtube-data'}   # database name\r\n",
    "\r\n",
    "    # Connecting to the database.\r\n",
    "    engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(db_config['user'],\r\n",
    "                                                                db_config['pwd'],\r\n",
    "                                                                db_config['host'],\r\n",
    "                                                                db_config['port'],\r\n",
    "                                                                db_config['db']))\r\n",
    "\r\n",
    "    # Creating an SQL query.\r\n",
    "    query = ''' SELECT * FROM trending_by_time '''\r\n",
    "\r\n",
    "    # Running the query and storing the result in the DataFrame.\r\n",
    "    print('COLLECT NEWEST DATASET')\r\n",
    "    df = pd.io.sql.read_sql(query, con = engine, index_col = 'Record Id')\r\n",
    "    print(df.info())\r\n",
    "    print('Sample of new dataset:', df.sample(5))\r\n",
    "    print()\r\n",
    "\r\n",
    "    # Creat/Update .csv file\r\n",
    "    print('CREATE/UPDATE NEWEST DATASET TO .CSV FILE')\r\n",
    "    df.to_csv(path+'trending_by_time.csv')\r\n",
    "    print()\r\n",
    "    print('DONE! CHECK FOLDER PATH FOR NEW .CSV FILE')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "73ebea03b847d5902fbebbee7826734ee32aa892399285cc47efc8035cc5db18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}